{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBayesian spam filter\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bayesian spam filter\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                    0\n",
       "word_freq_address                 0\n",
       "word_freq_all                  0.33\n",
       "word_freq_3d                      0\n",
       "word_freq_our                     0\n",
       "word_freq_over                 0.49\n",
       "word_freq_remove                  0\n",
       "word_freq_internet             1.32\n",
       "word_freq_order                0.16\n",
       "word_freq_mail                 5.12\n",
       "word_freq_receive                 0\n",
       "word_freq_will                    0\n",
       "word_freq_people                  0\n",
       "word_freq_report               0.66\n",
       "word_freq_addresses               0\n",
       "word_freq_free                    0\n",
       "word_freq_business             0.33\n",
       "word_freq_email                   0\n",
       "word_freq_you                  0.33\n",
       "word_freq_credit                  0\n",
       "word_freq_your                    0\n",
       "word_freq_font                    0\n",
       "word_freq_000                     0\n",
       "word_freq_money                   0\n",
       "word_freq_hp                      0\n",
       "word_freq_hpl                     0\n",
       "word_freq_george                  0\n",
       "word_freq_650                     0\n",
       "word_freq_lab                     0\n",
       "word_freq_labs                    0\n",
       "word_freq_telnet                  0\n",
       "word_freq_857                     0\n",
       "word_freq_data                    0\n",
       "word_freq_415                     0\n",
       "word_freq_85                   0.16\n",
       "word_freq_technology              0\n",
       "word_freq_1999                    0\n",
       "word_freq_parts                   0\n",
       "word_freq_pm                      0\n",
       "word_freq_direct                  0\n",
       "word_freq_cs                      0\n",
       "word_freq_meeting              0.16\n",
       "word_freq_original                0\n",
       "word_freq_project                 0\n",
       "word_freq_re                      0\n",
       "word_freq_edu                  0.33\n",
       "word_freq_table                   0\n",
       "word_freq_conference              0\n",
       "char_freq_;                       0\n",
       "char_freq_(                    0.07\n",
       "char_freq_[                   0.023\n",
       "char_freq_!                       0\n",
       "char_freq_$                       0\n",
       "char_freq_#                   0.023\n",
       "capital_run_length_average    1.552\n",
       "capital_run_length_longest       10\n",
       "capital_run_length_total        149\n",
       "ham                            True\n",
       "Id                             2660\n",
       "Name: 24, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 5.55 0.0 0.0 0.0 0.0 0.0 0.0 0.0 2.77 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 1.0 1 7 True 1103]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3680, 58)\n",
      "(58, 1)\n",
      "(3680,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-296-93017f2308f2>:94: RuntimeWarning: overflow encountered in exp\n",
      "  1 / (1 + np.exp(-x)),\n",
      "<ipython-input-296-93017f2308f2>:95: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(x) / (1 + np.exp(x)))\n",
      "<ipython-input-296-93017f2308f2>:95: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.exp(x) / (1 + np.exp(x)))\n"
     ]
    }
   ],
   "source": [
    "sample_email = \"make, address, 3d make FSERAS conference conference 1999 GREADER tragujsdkgsfo gfsgodhfguio fhguid fhgudfigufghdfui ghd hudihgihdfi huguidf hfdiguidf. iudfiguhdf gidfuhgdfhdfuigdif. guiduifhmake, address, table, conference, !!!!! directi  DSDASD\"\n",
    "words = []\n",
    "chars = []\n",
    "\n",
    "for c in data.columns[0:48]:\n",
    "    words.append(c[c.index(\"q_\")+2:])\n",
    "\n",
    "for c in data.columns[48:54]:\n",
    "    chars.append(c[c.index(\"q_\")+2:])\n",
    "    \n",
    "\n",
    "def parse_email(text):\n",
    "    wf = np.zeros(48)\n",
    "    cf = np.zeros(6)\n",
    "    crl_a = 0\n",
    "    crl_max = 0\n",
    "    crl_t = 0\n",
    "    total_words = 0\n",
    "    total_chars = len(text)\n",
    "    capital_words = 0\n",
    "    \n",
    "    text = text.split(' ')\n",
    "    total_words = len(text)\n",
    "    wds = []\n",
    "    for t in text:\n",
    "        # das capitals\n",
    "        \n",
    "        cap_run = 0 #capital run length\n",
    "        for i in range(len(t)):\n",
    "            if t[i].isupper():\n",
    "                cap_run +=1\n",
    "        \n",
    "        if cap_run > 0:\n",
    "            capital_words +=1\n",
    "        # check if current word length's cap len is greater than the max\n",
    "        if cap_run > crl_max: \n",
    "            crl_max = cap_run\n",
    "        \n",
    "        crl_t += cap_run\n",
    "        # now back to the lcase\n",
    "        t = t.lower()\n",
    "        \n",
    "        #   das special characters\n",
    "        if len(t) > 0:\n",
    "            if t[0] in chars:\n",
    "                cf[chars.index(t[0])] += 1\n",
    "            elif t[len(t)-1] in chars:\n",
    "                cf[chars.index(t[len(t)-1])] += 1\n",
    "            \n",
    "            if t[0].isalpha() != True and t[0].isnumeric() != True:\n",
    "                t = t[1:]\n",
    "            elif t[len(t)-1].isalpha() != True and t[len(t)-1].isnumeric() != True:\n",
    "                t = t[:-1]\n",
    "                \n",
    "        if t in words:\n",
    "            wf[words.index(t)] += 1\n",
    "\n",
    "    wf = (wf  * 100 / total_words);\n",
    "    cf = (cf * 100 / total_chars)\n",
    "    crl_a = crl_t / capital_words\n",
    "    \n",
    "\n",
    "    res = wf.tolist() + cf.tolist()\n",
    "    res.extend([crl_a, crl_max, crl_t])\n",
    "    return res\n",
    "    \n",
    "\n",
    "f = parse_email(sample_email)\n",
    "f = np.array(f).reshape((57, 1))\n",
    "thetas = np.random.randn(58,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y = data[['ham']].to_numpy().ravel()\n",
    "darr = data.drop(['ham', 'Id'], axis=1)\n",
    "\n",
    "X = darr.to_numpy()\n",
    "m = len(X)\n",
    "\n",
    "X = np.c_[np.zeros((len(X), 1)), X.reshape((len(X), 57))]\n",
    "\n",
    "print(X.shape)\n",
    "print(thetas.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "n = 1000\n",
    "eta = 0.01\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.where(x >= 0, \n",
    "                    1 / (1 + np.exp(-x)), \n",
    "                    np.exp(x) / (1 + np.exp(x)))\n",
    "\n",
    "\n",
    "for c in range(10):\n",
    "    for i in range(n):\n",
    "        ri = np.random.randint(m)\n",
    "        xi = X[ri:ri+1]\n",
    "        yi = Y[ri:ri+1]\n",
    "        prod = thetas.dot(xi)\n",
    "        grad = xi.T.dot(sigmoid(thetas.T.dot(xi.T)) - yi)\n",
    "        thetas = thetas - eta*grad\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parse_email(sample_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(res).reshape(1, 57)\n",
    "res = np.c_[0, res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-296-93017f2308f2>:94: RuntimeWarning: overflow encountered in exp\n",
      "  1 / (1 + np.exp(-x)),\n"
     ]
    }
   ],
   "source": [
    "y = sigmoid(thetas.T.dot(X[25].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
